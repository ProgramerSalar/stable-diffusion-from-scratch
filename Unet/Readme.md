# Stable Diffusion U-Net PyTorch Implementation

This repository contains a PyTorch implementation of a U-Net architecture with attention mechanisms, inspired by the architecture used in Stable Diffusion and other modern generative models. The code is modular, extensible, and designed for educational and research purposes.

---

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [File Structure](#file-structure)
- [Installation](#installation)
- [Usage](#usage)
  - [Model Construction](#model-construction)
  - [Forward Pass Example](#forward-pass-example)
- [Code Structure](#code-structure)
  - [Main Components](#main-components)
  - [Attention Mechanisms](#attention-mechanisms)
  - [Residual Blocks](#residual-blocks)
  - [Downsampling/Upsampling](#downsamplingupsampling)
  - [Timestep Embedding](#timestep-embedding)
- [Customization](#customization)
- [Extending the Model](#extending-the-model)
- [References](#references)
- [License](#license)

---

## Overview

The core of this repository is the [`Model`](unet.py) class in [unet.py](unet.py), which implements a flexible U-Net with optional attention layers and timestep embeddings. This architecture is commonly used in diffusion models for image generation, such as Stable Diffusion.

The model supports:
- Residual connections
- Group normalization
- Vanilla and linear attention
- Configurable depth and width
- Timestep embeddings for diffusion models

---

## Features

- **PyTorch Implementation**: Fully implemented using PyTorch, making it easy to integrate with other PyTorch-based projects.
- **Attention Support**: Includes both standard ("vanilla") and efficient ("linear") attention mechanisms.
- **Residual Blocks**: Uses ResNet-style blocks for stable training and deep architectures.
- **Flexible Architecture**: Easily configurable number of channels, resolution, attention resolutions, and more.
- **Timestep Embedding**: Supports timestep embeddings for use in diffusion models.
- **Modular Design**: Components such as attention, normalization, and up/downsampling are modular and reusable.

---

## File Structure
```
attention.py # Linear attention module 
unet.py # Main U-Net model and building blocks 
Readme.md # This documentation 
```


---

## Usage
Model Construction
You can construct the model by importing the **Model** class from `unet`.py:

```python
from unet import Model

model = Model(
    ch=128,
    out_ch=3,
    num_res_blocks=2,
    attn_resolutions=[16],
    in_channels=3,
    resolution=256,
    ch_mult=(1, 1, 2, 2, 4)
)
```

Forward Pass Example

```python
import torch
from unet import Model

x = torch.randn(1, 3, 256, 256)  # Example input image
t = torch.tensor([1000])         # Example timestep

model = Model(
    ch=128,
    out_ch=3,
    num_res_blocks=2,
    attn_resolutions=[16],
    in_channels=3,
    resolution=256,
    ch_mult=(1, 1, 2, 2, 4)
)

output = model(x, t)
print(output.shape)  # Output: torch.Size([1, 3, 256, 256])

```

## Code Structure

Main Components

- `Model`: The main U-Net model class.
- `ResnetBlock`: Residual block with optional timestep embedding.
- `AttentionBlock`: Standard attention block.
- `LinearAttentionBlock`: Efficient linear attention block.
- `Upsample`: Upsampling layer.
- `Downsample`: Downsampling layer.
- `Normalize`: Group normalization.
get_timestep_embedding: Generates sinusoidal timestep embeddings.

Attention Mechanisms

The model supports two types of attention:

- **Vanilla Attention**: Standard self-attention as in transformers.
- **Linear Attention**: Efficient attention mechanism from `attention.py` using the `LinearAttention` class.

You can select the attention type via the attn_type or use_linear_attn parameters.

Residual Blocks

The `ResnetBlock` implements a standard residual block with optional convolutional shortcut and timestep embedding projection. This is used throughout the U-Net for stable and deep architectures.

Downsampling/Upsampling

- `Downsample`: Reduces spatial resolution, optionally with a convolution.
- `Upsample`: Increases spatial resolution, optionally with a convolution.

Timestep Embedding

The model supports timestep embeddings for use in diffusion models. The embedding is generated by `get_timestep_embedding` and projected through two linear layers.



## Customization
You can customize the model by changing the following parameters:


- `ch`: Base channel count.
- `out_ch`: Number of output channels.
- `ch_mult`: Tuple of multipliers for each resolution level.
- `num_res_blocks`: Number of residual blocks per resolution.
- `attn_resolutions`: List of resolutions at which to apply attention.
- `dropout`: Dropout rate in residual blocks.
- `resamp_with_conv`: Whether to use convolution in up/downsampling.
- `in_channels`: Number of input channels.
- `resolution`: Input image resolution.
- `use_timestep`: Whether to use timestep embedding.
- `use_linear_attn`: Whether to use linear attention.
- `attn_type`: Type of attention ("vanilla", "linear", or "none").


## Extending the Model

- **Add More Attention Types**: Implement new attention mechanisms in attention.py and update make_attention.
- **Conditional Inputs**: Pass additional context to the model via the context argument in the forward method.
- **Different Normalization**: Swap out Normalize for other normalization layers as needed.
- **Custom Residual Blocks**: Extend ResnetBlock for more complex architectures.